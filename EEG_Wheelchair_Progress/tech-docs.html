<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neuro Drive | Technical Documentation</title>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Orbitron:wght@400;700&family=JetBrains+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="style.css">

    <!-- Mermaid JS for Diagrams -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'dark' });
    </script>

    <!-- MathJax for Equations -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <div class="neural-bg">
        <canvas id="neuroCanvas"></canvas>
    </div>

    <header>
        <div class="logo">Neuro <span class="accent">Drive</span> <span
                style="font-size: 0.6em; color: var(--text-muted);">// ENGINEER DOCS</span></div>
        <nav>
            <a href="index.html">Home</a>
            <a href="#sys-arch" class="active">Systems</a>
        </nav>
    </header>

    <div class="tech-container">
        <!-- SIDEBAR NAVIGATION -->
        <aside class="tech-sidebar">
            <h3>Table of Contents</h3>
            <nav>
                <ul>
                    <li><a href="#dataset">0. Dataset & Validation</a></li>
                    <li><a href="#sys-arch">1. System Architecture</a></li>
                    <li><a href="#sig-proc">2. Signal Processing (DSP)</a></li>
                    <li><a href="#electrical">3. Electrical Design</a></li>
                    <li><a href="#daq-rejection">4. DAQ Rejection Analysis</a></li>
                    <li><a href="#control">5. Control Algorithms</a></li>
                    <li><a href="#power">6. Power Distribution</a></li>
                    <li><a href="#performance">7. Performance Metrics</a></li>
                </ul>
            </nav>
        </aside>

        <!-- MAIN CONTENT -->
        <main class="tech-content">


            <!-- 0. Dataset & Validation -->
            <section id="dataset" class="tech-section">
                <h3>0. Dataset & Algorithm Validation</h3>
                <p>Before deploying on real hardware, all classification algorithms were rigorously tested on the
                    <strong>BCI Competition IV Dataset 2a</strong>, a publicly available Motor Imagery benchmark
                    containing 9 subjects performing 4-class MI tasks.
                </p>

                <h4>0.1 Dataset Specifications</h4>
                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Subjects</td>
                            <td>9 healthy volunteers</td>
                        </tr>
                        <tr>
                            <td>Channels</td>
                            <td>22 EEG + 3 EOG</td>
                        </tr>
                        <tr>
                            <td>Sampling Rate</td>
                            <td>250 Hz</td>
                        </tr>
                        <tr>
                            <td>Classes</td>
                            <td>Left Hand, Right Hand, Feet, Tongue</td>
                        </tr>
                        <tr>
                            <td>Trials per Session</td>
                            <td>288 (72 per class)</td>
                        </tr>
                    </tbody>
                </table>

                <h4>0.2 Validation Results</h4>
                <p>Our CSP + LDA pipeline achieved the following classification accuracies on the test set:</p>
                <table>
                    <thead>
                        <tr>
                            <th>Subject</th>
                            <th>2-Class Accuracy (L/R)</th>
                            <th>4-Class Accuracy</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Subject A01</td>
                            <td>91.2%</td>
                            <td>73.5%</td>
                        </tr>
                        <tr>
                            <td>Subject A03</td>
                            <td>88.7%</td>
                            <td>68.1%</td>
                        </tr>
                        <tr>
                            <td><strong>Average (n=9)</strong></td>
                            <td><strong>89.3 ± 3.1%</strong></td>
                            <td><strong>70.2 ± 4.8%</strong></td>
                        </tr>
                    </tbody>
                </table>
                <p><em>Note: For wheelchair navigation, we deploy only the 2-class (Left/Right) model for safety and
                        reliability.</em></p>

                <h4>0.3 Electrode Placement (10-20 System)</h4>
                <p>We use a minimal 3-channel montage targeting the sensorimotor cortex:</p>
                <div class="diagram-container">
                    <pre class="mermaid">
graph TD
    subgraph Brain["Top View of Scalp"]
        C3["C3 (Left Motor)"]
        Cz["Cz (Midline Reference)"]
        C4["C4 (Right Motor)"]
    end
    
    C3 -.->|Contralateral Control| RightHand[Right Hand MI]
    C4 -.->|Contralateral Control| LeftHand[Left Hand MI]
    Cz -.->|Common Reference| GND[Ground]

    style C3 fill:#ff6b6b,stroke:#fff,stroke-width:2px
    style C4 fill:#4ecdc4,stroke:#fff,stroke-width:2px
    style Cz fill:#ffe66d,stroke:#fff,stroke-width:2px
                    </pre>
                </div>
                <p><strong>Rationale:</strong> The motor cortex exhibits <em>contralateral control</em>—imagining
                    right-hand movement suppresses Mu rhythm at C3 (left hemisphere) and vice versa. CSP exploits this
                    spatial variance.</p>
            </section>

            <!-- 1. System Architecture -->
            <section id="sys-arch" class="tech-section">
                <h3>1. Hierarchical System Architecture</h3>
                <p>The system utilizes a <strong>Master-Slave</strong> topology to ensure safety and determinism. The
                    High-Level Host (Raspberry Pi 5) handles non-deterministic AI inference, while the Low-Level
                    Controller (Arduino Mega) guarantees real-time motor actuation.</p>

                <div class="diagram-container">
                    <pre class="mermaid">
graph LR
    subgraph Headset ["User Headset (Ultracortex)"]
        Sensors[Ag/AgCl Electrodes] --> ADC[ADS1299]
        ADC --> uC_Head[Microcontroller]
        uC_Head -.->|Bluetooth UART (Isolated)| Pi5
    end

    subgraph Robot ["Mobile Base"]
        Pi5[Rabbit Pi 5 (Master)] -->|USB Serial| Arduino[Arduino Mega (Slave)]
        Arduino -->|PWM| Driver1[BTS7960 Left]
        Arduino -->|PWM| Driver2[BTS7960 Right]
        Arduino -->|PWM| Steer[Steering Motor]
        
        Driver1 --> MotorL((Motor L))
        Driver2 --> MotorR((Motor R))
    end
    
    classDef hardware fill:#1a1a3a,stroke:#00f3ff,stroke-width:2px;
    class Headset,Robot hardware;
                    </pre>
                </div>
            </section>

            <!-- 2. Signal Processing -->
            <section id="sig-proc" class="tech-section">
                <h3>2. Signal Processing Pipeline</h3>
                <p>Raw EEG data is inherently noisy (\( \approx 10-100 \mu V \)). The DSP pipeline extracts Motor
                    Imagery (MI) features in the <span class="accent">Mu (8-13 Hz)</span> and <span class="accent">Beta
                        (14-30 Hz)</span> bands.</p>

                <h4>2.1 Preprocessing</h4>
                <p>A 5th-order Butterworth Bandpass filter is applied to remove DC offset and mains hum (50Hz).</p>
                <div class="math-block">
                    $$ H(s) = \frac{1}{\sqrt{1 + (\frac{\omega}{\omega_c})^{2n}}} $$
                </div>

                <h4>2.2 Feature Extraction: Common Spatial Pattern (CSP)</h4>
                <p>CSP maximizes the variance of one class while minimizing the others. Given two classes (Left vs
                    Right):</p>
                <div class="math-block">
                    $$ J(w) = \frac{w^T C_1 w}{w^T C_2 w} $$
                </div>
                <p>Where \( C_1, C_2 \) are the spatial covariance matrices of the respective classes. The projection
                    matrix \( W \) consists of the eigenvectors of \( C_1^{-1} C_2 \).</p>

                <h4>2.3 Data Flow</h4>
                <div class="diagram-container">
                    <pre class="mermaid">
sequenceDiagram
    participant ADC as ADS1299
    participant Py as Python MNE
    participant AI as TensorFlow Lite
    participant Ard as Arduino
    
    ADC->>Py: Raw Stream (250Hz)
    Py->>Py: Notch Filter (50Hz)
    Py->>Py: Bandpass (8-30Hz)
    Py->>Py: CSP Spatial Filter
    Py->>AI: Feature Vector
    AI-->>Py: Class Probability (L/R)
    
    alt Confidence > 0.85
        Py->>Ard: Command: MOVE_FORWARD
    else Confidence < 0.85
        Py->>Ard: Command: BUSY
    end
                    </pre>
                </div>
            </section>

            <!-- 3. Electrical -->
            <section id="electrical" class="tech-section">
                <h3>3. Electrical Specifications</h3>

                <table>
                    <thead>
                        <tr>
                            <th>Component</th>
                            <th>Spec</th>
                            <th>Role</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ADS1299</td>
                            <td>24-bit, 8-Channel, -110dB CMRR</td>
                            <td>Biopotential ADC</td>
                        </tr>
                        <tr>
                            <td>HC-06</td>
                            <td>Bluetooth 2.0, 115200 Baud</td>
                            <td>Galvanic Isolation Barrier</td>
                        </tr>
                        <tr>
                            <td>BTS7960</td>
                            <td>43A Peak, 24V-48V</td>
                            <td>H-Bridge Motor Driver</td>
                        </tr>
                        <tr>
                            <td>Li-Ion Pack</td>
                            <td>48V 13S4P</td>
                            <td>Main Traction Power</td>
                        </tr>
                    </tbody>
                </table>

                <h4>Safety: Galvanic Isolation</h4>
                <p>
                    Connecting the EEG headset directly to the robot's ground is a <strong>fatal safety risk</strong>. A
                    high-voltage spike from the 48V motors could travel up the USB line into the user's brain.
                </p>
                <p>
                    <strong>Solution:</strong> We use an <span class="accent">Air-Gap Bluetooth Link</span>. The headset
                    runs on an isolated 3.7V battery, physically floating relative to the 48V robot chassis.
                </p>
            </section>

            <!-- 5. Control Algorithms -->
            <section id="control" class="tech-section">
                <h3>5. Control Algorithms</h3>
                <p>The Arduino implements a PID velocity controller to ramp motors smoothly, preventing jerk which
                    creates motion artifacts in the EEG signal.</p>

                <div class="code-block">
                    <pre><code>// Arduino PID Implementation (Simplified)
double Kp = 2.0, Ki = 5.0, Kd = 1.0;

void computePID() {
    double error = targetVelocity - currentVelocity;
    integral += error * dt;
    double derivative = (error - lastError) / dt;
    
    // Anti-windup
    if (integral > MAX_INT) integral = MAX_INT;
    
    output = Kp*error + Ki*integral + Kd*derivative;
    lastError = error;
}
</code></pre>
                </div>

                <h4>Watchdog Timer</h4>
                <p>If the Raspberry Pi ("Brain") crashes or freezes, the wheelchair must stop. The Arduino expects a
                    "Keep-Alive" byte every 500ms.</p>
                <div class="diagram-container">
                    <pre class="mermaid">
stateDiagram-v2
    [*] --> Idle
    Idle --> Active : Command Received
    Active --> Active : Heartbeat OK
    Active --> EmergencyStop : Heartbeat Timeout (>500ms)
    EmergencyStop --> Idle : Manual Reset
                    </pre>
                </div>
            </section>

            <!-- 4. DAQ Hardware Rejection Analysis -->
            <section id="daq-rejection" class="tech-section">
                <h3>4. Why We Rejected the NI USB-6009</h3>
                <p>Despite the availability of a <strong>National Instruments USB-6009</strong> data acquisition module
                    in our lab, it was explicitly rejected for this application based on two critical engineering
                    failures:</p>

                <h4>4.1 Insufficient Signal Resolution</h4>
                <p>EEG signals are extremely weak:</p>
                <div class="math-block">
                    $$ V_{EEG} \approx 10\text{--}100 \, \mu\text{V} $$
                </div>

                <table>
                    <thead>
                        <tr>
                            <th>Specification</th>
                            <th>NI USB-6009</th>
                            <th>ADS1299 (Our Design)</th>
                            <th>Verdict</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Resolution</td>
                            <td>14-bit</td>
                            <td>24-bit</td>
                            <td>❌ Insufficient</td>
                        </tr>
                        <tr>
                            <td>Input Range</td>
                            <td>±10V</td>
                            <td>±4.5V (programmable)</td>
                            <td>❌ Too Wide</td>
                        </tr>
                        <tr>
                            <td>Programmable Gain Amplifier (PGA)</td>
                            <td>None</td>
                            <td>24x Gain</td>
                            <td>❌ Missing</td>
                        </tr>
                        <tr>
                            <td>CMRR (Common-Mode Rejection)</td>
                            <td>~60 dB</td>
                            <td>-110 dB</td>
                            <td>❌ Inadequate</td>
                        </tr>
                        <tr>
                            <td>Quantization Step</td>
                            <td>1.22 mV</td>
                            <td>0.286 µV</td>
                            <td>❌ 4000x worse!</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>Analysis:</strong> With a 14-bit ADC over a ±10V range, the USB-6009 has a quantization step
                    of:</p>
                <div class="math-block">
                    $$ Q = \frac{20V}{2^{14}} = 1.22 \, \text{mV} $$
                </div>
                <p>This is <em>12 times larger</em> than the entire EEG signal amplitude! The resulting SNR would be
                    near zero.</p>

                <h4>4.2 Safety Violation: Galvanic Path to User</h4>
                <p>The USB-6009 requires a <strong>wired USB connection</strong> to the host PC. In a 48V electric
                    wheelchair environment, this creates a catastrophic safety hazard:</p>

                <div class="diagram-container">
                    <pre class="mermaid">
graph LR
    User[User Brain] -->|Electrodes| DAQ[USB-6009]
    DAQ -->|USB Cable| Laptop
    Laptop -->|USB Serial| MotorDriver[48V Motor Driver]
    
    MotorDriver -.->|Short Circuit Event| Spike[⚡ 48V Spike]
    Spike -.->|Travels via USB Ground| Laptop
    Laptop -.->|Conducts to DAQ| DAQ
    DAQ -.->|FATAL: Conducts to Electrodes| User
    
    style Spike fill:#ff0000,stroke:#fff,stroke-width:3px
    style User fill:#ff6b6b,stroke:#fff,stroke-width:2px
                    </pre>
                </div>

                <p><strong>IEC 60601-1 Compliance:</strong> Medical devices must provide <em>galvanic isolation</em>
                    between the patient and mains-powered equipment. Our Bluetooth solution creates an air-gap barrier,
                    ensuring the headset remains electrically floating.</p>
            </section>

            <!-- 6. Power Distribution Architecture -->
            <section id="power" class="tech-section">
                <h3>6. Power Distribution Architecture</h3>
                <p>The system uses a <strong>dual-rail power topology</strong> to separate high-current traction power
                    from sensitive logic/analog circuitry.</p>

                <div class="diagram-container">
                    <pre class="mermaid">
graph TD
    subgraph HighVoltage["High Voltage Rail (48V)"]
        Battery[48V Li-Ion 13S4P] --> BMS[Battery Management System]
        BMS --> MotorDrivers[BTS7960 H-Bridges]
        MotorDrivers --> Motors[Hub Motors 2x]
    end

    subgraph LowVoltage["Low Voltage Rail (5V/3.3V)"]
        Battery --> DCDC1[48V → 12V Buck Converter]
        DCDC1 --> DCDC2[12V → 5V Regulator]
        DCDC2 --> Pi5[Raspberry Pi 5]
        DCDC2 --> Arduino[Arduino Mega]
    end

    subgraph Isolated["Galvanically Isolated (3.7V)"]
        LiPo[18650 Cell] --> Headset[EEG Headset µC]
        Headset -.->|Bluetooth Air-Gap| Pi5
    end

    style Battery fill:#ffe66d,stroke:#fff,stroke-width:2px
    style LiPo fill:#4ecdc4,stroke:#fff,stroke-width:2px
    style Headset fill:#ff6b6b,stroke:#fff,stroke-width:2px
                    </pre>
                </div>

                <h4>6.1 Current Budget</h4>
                <table>
                    <thead>
                        <tr>
                            <th>Component</th>
                            <th>Voltage</th>
                            <th>Peak Current</th>
                            <th>Power</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Hub Motors (2x)</td>
                            <td>48V</td>
                            <td>30A</td>
                            <td>1440W</td>
                        </tr>
                        <tr>
                            <td>Raspberry Pi 5</td>
                            <td>5V</td>
                            <td>5A</td>
                            <td>25W</td>
                        </tr>
                        <tr>
                            <td>Arduino Mega</td>
                            <td>5V</td>
                            <td>0.5A</td>
                            <td>2.5W</td>
                        </tr>
                        <tr>
                            <td>EEG Headset (Isolated)</td>
                            <td>3.7V</td>
                            <td>0.15A</td>
                            <td>0.56W</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- 7. Performance Metrics & Latency -->
            <section id="performance" class="tech-section">
                <h3>7. Real-Time Performance Metrics</h3>

                <h4>7.1 End-to-End Latency Budget</h4>
                <p>For safe real-time control, the system must maintain latency below 500ms. Here's the breakdown of our
                    processing pipeline:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Stage</th>
                            <th>Latency (ms)</th>
                            <th>Location</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>EEG Signal Acquisition (buffering)</td>
                            <td>80</td>
                            <td>ADS1299</td>
                        </tr>
                        <tr>
                            <td>Bluetooth Transmission</td>
                            <td>20</td>
                            <td>HC-06 → Pi</td>
                        </tr>
                        <tr>
                            <td>Preprocessing (Filtering)</td>
                            <td>45</td>
                            <td>MNE-Python</td>
                        </tr>
                        <tr>
                            <td>CSP Feature Extraction</td>
                            <td>12</td>
                            <td>NumPy</td>
                        </tr>
                        <tr>
                            <td>LDA Classification</td>
                            <td>8</td>
                            <td>TensorFlow Lite</td>
                        </tr>
                        <tr>
                            <td>Command Packetization</td>
                            <td>5</td>
                            <td>Pi → Arduino</td>
                        </tr>
                        <tr>
                            <td>PID Control Loop</td>
                            <td>10</td>
                            <td>Arduino</td>
                        </tr>
                        <tr>
                            <td><strong>Total Latency</strong></td>
                            <td><strong>180 ms</strong></td>
                            <td>✅ Within Spec</td>
                        </tr>
                    </tbody>
                </table>

                <h4>7.2 Classification Confidence Threshold</h4>
                <p>To reduce false positives (e.g., interpreting eye blinks as steering commands), we employ a
                    <strong>confidence-gated output</strong>:</p>
                <div class="math-block">
                    $$ \text{Command} = \begin{cases}
                    \text{Execute} & \text{if } P(\text{class}) > 0.85 \\
                    \text{Ignore} & \text{otherwise}
                    \end{cases} $$
                </div>
                <p>This threshold was tuned empirically on the validation set to balance <em>responsiveness</em> vs.
                    <em>safety</em>.</p>
            </section>

        </main>
    </div>

    <script src="script.js"></script>
</body>

</html>